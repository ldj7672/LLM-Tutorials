{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMubx/7mnlQDfzIK11SZY30",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldj7672/LLM-Tutorials/blob/main/examples/OpenAI_RAG_Llama_index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OpenAI와 Llama-index를 이용한 RAG 실습**\n",
        "\n",
        "**OpenAI**와 **Llama-index**를 이용한, 조금 더 다양한 기능의 **RAG** 기능을 구현해보는 실습 코드입니다."
      ],
      "metadata": {
        "id": "IgzEw-9FeGka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. 환경 세팅**\n",
        "- 필요 라이브러리 설치\n",
        "- API Key 입력\n",
        "- 구글 드라이브 마운트"
      ],
      "metadata": {
        "id": "cml80vUosW3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai llama-index llama-index-vector-stores-chroma"
      ],
      "metadata": {
        "id": "igHt8WP8SLxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48572a96-b3f6-4c3b-ba48-4a8b0df8357f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.2/374.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.4/187.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import chromadb\n",
        "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
        "from IPython.display import Markdown, display\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext, get_response_synthesizer\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding"
      ],
      "metadata": {
        "id": "71WAf2fMVKI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab에 API 키를 안전하게 입력받기\n",
        "api_key = getpass(\"OpenAI API 키를 입력하세요: \")\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmIPe8Kvsjav",
        "outputId": "b0593bdc-a09f-4832-b125-9557113adbc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API 키를 입력하세요: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E87KkLX5VIIx",
        "outputId": "02f9d032-bb7a-4f43-ee1f-8f0ca716be5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. 기본 예제**\n",
        "- 지정된 디렉토리에서 문서를 읽고, 이 문서들로부터 `VectorStoreIndex`를 생성하고, 이 인덱스를 쿼리 엔진으로 변환하여 입력된 쿼리와 관련된 정보를 검색하는 **가장 기본적인 예제**\n",
        "- 별도의 임베딩 모델이나 ChromaDB 같은 외부 벡터 저장소를 지정하지 않기 때문에 세밀한 조정은 불가능."
      ],
      "metadata": {
        "id": "uD6KA2m4W7Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG 참조 문서 디렉토리 지정 (각자 지정 필요)\n",
        "documents_dir = '/content/drive/MyDrive/코드 예제/LLM/ref_docs_2'"
      ],
      "metadata": {
        "id": "q-4tnJON5SFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서를 읽어와 인덱스를 생성하고, 간단한 쿼리 엔진으로 검색하는 기본 예제입니다.\n",
        "documents = SimpleDirectoryReader(documents_dir).load_data()\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "OZsVKc9mS40S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인덱스를 사용해 간단한 쿼리 엔진을 생성합니다.\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"KBO 한국 시리즈에서 우승하지 못한 팀을 알려줘\")\n",
        "display(Markdown(f\"{response}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2400DQuS_VM",
        "outputId": "505cbca1-cfd8-4ae8-c4e6-6cc5dae03a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "삼성 라이온즈\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. ChromaDB와 OpenAI Embedding 모델 사용 예제**\n",
        "\n",
        "- 벡터 저장소로 ChromaDB를 통합하고 `OpenAIEmbedding`을 사용하여 커스텀 임베딩 모델을 정의\n",
        "- 메모리 상에 ChromaDB 클라이언트와 컬렉션을 초기화하고, `ChromaVectorStore`를 설정하여 데이터를 저장한 후 해당 저장소와 임베딩 모델을 사용하여 인덱스를 생성\n",
        "- 기본 예제와 달리, **임베딩 모델**과 **벡터 저장소**를 명시적으로 설정하여 **검색 정확도를 높일 수 있는 방법**"
      ],
      "metadata": {
        "id": "H5Ku_r7MTF_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ChromaDB 클라이언트를 메모리상에 생성하고 새로운 컬렉션을 만듭니다.\n",
        "chroma_client = chromadb.EphemeralClient()  # 메모리 상에 저장 (세션 간 데이터 유지가 필요 없다면 이 옵션 사용)\n",
        "chroma_collection = chroma_client.create_collection(\"quickstart\")  # 컬렉션 생성은 최초 1회만 실행합니다."
      ],
      "metadata": {
        "id": "vEpyDRf3THPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI 임베딩 모델을 정의합니다. (필요에 따라 모델을 변경할 수 있습니다.)\n",
        "embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
        "\n",
        "# 문서들을 지정된 디렉토리에서 불러옵니다.\n",
        "documents = SimpleDirectoryReader(documents_dir).load_data()\n",
        "\n",
        "# ChromaVectorStore를 설정하고 데이터를 저장합니다.\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# 문서들로부터 인덱스를 생성합니다. 이때 ChromaDB와 임베딩 모델을 사용합니다.\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context, embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "id": "_ZEiL7wJwYd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 쿼리 엔진을 사용하여 질문에 답변합니다.\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "# 예시 쿼리: 한국 시리즈에서 우승하지 못한 팀을 알려줘\n",
        "response = query_engine.query(\"한국 시리즈에서 우승하지 못한 팀을 알려줘\")\n",
        "display(Markdown(f\"{response}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "VIFycIgDwlaA",
        "outputId": "b4e35f0a-9412-4683-de4a-a7948804f91a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "키움 히어로즈"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. 고급 검색 및 후처리 사용 예제**\n",
        "- 검색 프로세스에 대해 더 세밀한 제어를 제공하는 방법\n",
        "- `VectorIndexRetriever`를 설정하여 **`similarity_top_k`** 파라미터 조절\n",
        "- `get_response_synthesizer()`를 사용하여 검색된 문서와 쿼리를 합치는 합성기를 정의\n",
        "- `SimilarityPostprocessor`의 **`similarity_cutoff`** 로 결과 필터링\n",
        "\n",
        "- **`similarity_top_k`**\n",
        "  - 유사한 문서의 개수를 조절\n",
        "  - 값이 높으면 더 많은 문서를 검색하지만, 불필요한 정보가 포함될 수 있음\n",
        "- **`similarity_cutoff`**\n",
        "  - 검색된 문서 중 유사도가 일정 수준 이상인 것만 포함\n",
        "  - 값을 낮추면 더 많은 결과를 포함하지만, 정확도가 떨어질 수 있음"
      ],
      "metadata": {
        "id": "aJ9prQ-fTUcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 리트리버를 설정합니다. 'similarity_top_k'로 유사한 문서의 개수를 조절할 수 있습니다.\n",
        "retriever = VectorIndexRetriever(\n",
        "    index=index,  # 기존에 생성한 인덱스를 불러옵니다.\n",
        "    similarity_top_k=10,  # 유사한 문서 최대 10개를 선택합니다.\n",
        ")\n",
        "\n",
        "# 검색된 문서와 쿼리를 합성해주는 합성기를 가져옵니다.\n",
        "response_synthesizer = get_response_synthesizer()\n",
        "\n",
        "# 쿼리 엔진을 생성합니다. 후처리 단계에서 'similarity_cutoff'를 설정하여 유사도가 낮은 결과를 필터링할 수 있습니다.\n",
        "query_engine = RetrieverQueryEngine(\n",
        "    retriever=retriever,\n",
        "    response_synthesizer=response_synthesizer,\n",
        "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.1)],  # 유사도가 0.1 이하인 결과는 제외\n",
        ")"
      ],
      "metadata": {
        "id": "dFdUJrJBTJBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"KBO에서 가장 유명한 사건 3개를 알려줘\")\n",
        "display(Markdown(f\"{response}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "uPks9NsRXoT6",
        "outputId": "283facf2-8569-4dd7-b10d-b411f0e21f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "삼청태, 삼성의 대구 유니폼, 그리고 2023 월드 베이스볼 클래식에서의 이강철호의 3대회 연속 1라운드 탈락이 KBO에서 가장 유명한 사건 3개입니다."
          },
          "metadata": {}
        }
      ]
    }
  ]
}